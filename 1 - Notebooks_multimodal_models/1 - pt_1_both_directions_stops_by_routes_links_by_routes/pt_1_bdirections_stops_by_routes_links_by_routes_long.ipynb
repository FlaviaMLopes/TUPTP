{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Frequency_tables_long_format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "from shapely.geometry import Point, LineString, shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the connection with the DB (optional)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Step 1: Create the connection with the DB\n",
    "engine = create_engine(\"postgresql://urbaninfo:@cirrus.ita.chalmers.se/se_tuptp\")\n",
    "conn = engine.connect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Step 2: Create a new schema when it is necessary\n",
    "#schema = '''CREATE SCHEMA name_schema'''\n",
    "#conn.execute(schema)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Expanded Table\n",
    "\n",
    "###### To create the frequency model, it is necessary first to compile a table containing all the trips that occur on the days covered by the GTFS."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Step 1: Import data\n",
    "# In this example, we are utilizing data from Västra Götaland, although these can be modified based on specific requirements.\n",
    "# links_pt_0\n",
    "links_pt_0_query = text('SELECT * FROM pt_0_baseline.links_pt_0')\n",
    "links_pt_0 = gpd.read_postgis(links_pt_0_query, engine, geom_col='geometry')\n",
    "\n",
    "# nodes_pt_0\n",
    "nodes_pt_0_query = text('''SELECT * FROM pt_0_baseline.nodes_pt_0''')\n",
    "nodes_pt_0 = gpd.read_postgis(nodes_pt_0_query, engine, geom_col='geometry')\n",
    "\n",
    "#calendar_dates_gtfs\n",
    "calendar_dates_gtfs_query = text('''SELECT * FROM p1_gtfs.regional_calendardates''')\n",
    "calendar_dates_gtfs = pd.read_sql(calendar_dates_gtfs_query, engine)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   service_id       date  exception_type   day_week  day_type week_start  \\\n0           1 2022-08-15               1     Monday  week_day 2022-08-15   \n1           1 2022-08-16               1    Tuesday  week_day 2022-08-15   \n2           1 2022-08-17               1  Wednesday  week_day 2022-08-15   \n3           1 2022-08-18               1   Thursday  week_day 2022-08-15   \n4           1 2022-08-19               1     Friday  week_day 2022-08-15   \n\n   week_number  \n0           33  \n1           33  \n2           33  \n3           33  \n4           33  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>service_id</th>\n      <th>date</th>\n      <th>exception_type</th>\n      <th>day_week</th>\n      <th>day_type</th>\n      <th>week_start</th>\n      <th>week_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2022-08-15</td>\n      <td>1</td>\n      <td>Monday</td>\n      <td>week_day</td>\n      <td>2022-08-15</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2022-08-16</td>\n      <td>1</td>\n      <td>Tuesday</td>\n      <td>week_day</td>\n      <td>2022-08-15</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2022-08-17</td>\n      <td>1</td>\n      <td>Wednesday</td>\n      <td>week_day</td>\n      <td>2022-08-15</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2022-08-18</td>\n      <td>1</td>\n      <td>Thursday</td>\n      <td>week_day</td>\n      <td>2022-08-15</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2022-08-19</td>\n      <td>1</td>\n      <td>Friday</td>\n      <td>week_day</td>\n      <td>2022-08-15</td>\n      <td>33</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the calendar_dates data\n",
    "# Step 2: Adjust the date format\n",
    "calendar_dates_gtfs['date'] = pd.to_datetime(calendar_dates_gtfs['date'], format='%Y%m%d')\n",
    "\n",
    "# Step 3: Create a column with the day of the week\n",
    "calendar_dates_gtfs['day_week'] = calendar_dates_gtfs['date'].dt.day_name()\n",
    "\n",
    "# Step 4: Create a column with the day type\n",
    "day_type_dict = {\n",
    "    'Monday': 'week_day',\n",
    "    'Tuesday': 'week_day',\n",
    "    'Wednesday': 'week_day',\n",
    "    'Thursday': 'week_day',\n",
    "    'Friday': 'week_day',\n",
    "    'Saturday': 'weekend',\n",
    "    'Sunday': 'weekend'\n",
    "}\n",
    "\n",
    "calendar_dates_gtfs['day_type'] = calendar_dates_gtfs['day_week'].map(day_type_dict)\n",
    "\n",
    "# Step 5: Create the week_start and week_number columns based on the date\n",
    "calendar_dates_gtfs['week_start'] = calendar_dates_gtfs['date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "calendar_dates_gtfs['week_number'] = calendar_dates_gtfs['week_start'].dt.isocalendar().week\n",
    "\n",
    "# Step 6 (optional): Display the temporary results\n",
    "calendar_dates_gtfs.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "             source            target route_short_name         mode  \\\n0  9022014001760012  9022014006242004               50  bus_service   \n1  9022014001760012  9022014006242004               50  bus_service   \n2  9022014001760012  9022014006242004               50  bus_service   \n3  9022014001760012  9022014006242004               50  bus_service   \n4  9022014001760012  9022014006242004               50  bus_service   \n\n   time_distance time_period          route_id  service_id  \\\n0           97.0  night_dawn  9011014505000000           5   \n1           97.0  night_dawn  9011014505000000           5   \n2           97.0  night_dawn  9011014505000000           5   \n3           97.0  night_dawn  9011014505000000           5   \n4           97.0  night_dawn  9011014505000000           5   \n\n              trip_id  direction_id  ...  stop_name_source stop_name_target  \\\n0  141010001054458148             0  ...      Brunnsparken        Stenpiren   \n1  141010001054458148             0  ...      Brunnsparken        Stenpiren   \n2  141010001054458148             0  ...      Brunnsparken        Stenpiren   \n3  141010001054458148             0  ...      Brunnsparken        Stenpiren   \n4  141010001054458148             0  ...      Brunnsparken        Stenpiren   \n\n  place_id_source  place_id_target  \\\n0       145235353        145235353   \n1       145235353        145235353   \n2       145235353        145235353   \n3       145235353        145235353   \n4       145235353        145235353   \n\n                                            geometry       date  day_week  \\\n0  LINESTRING (319300.968 6400118.943, 318713.953... 2022-07-31    Sunday   \n1  LINESTRING (319300.968 6400118.943, 318713.953... 2022-08-06  Saturday   \n2  LINESTRING (319300.968 6400118.943, 318713.953... 2022-08-07    Sunday   \n3  LINESTRING (319300.968 6400118.943, 318713.953... 2022-08-13  Saturday   \n4  LINESTRING (319300.968 6400118.943, 318713.953... 2022-08-14    Sunday   \n\n  day_type week_start week_number  \n0  weekend 2022-07-25          30  \n1  weekend 2022-08-01          31  \n2  weekend 2022-08-01          31  \n3  weekend 2022-08-08          32  \n4  weekend 2022-08-08          32  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>target</th>\n      <th>route_short_name</th>\n      <th>mode</th>\n      <th>time_distance</th>\n      <th>time_period</th>\n      <th>route_id</th>\n      <th>service_id</th>\n      <th>trip_id</th>\n      <th>direction_id</th>\n      <th>...</th>\n      <th>stop_name_source</th>\n      <th>stop_name_target</th>\n      <th>place_id_source</th>\n      <th>place_id_target</th>\n      <th>geometry</th>\n      <th>date</th>\n      <th>day_week</th>\n      <th>day_type</th>\n      <th>week_start</th>\n      <th>week_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9022014001760012</td>\n      <td>9022014006242004</td>\n      <td>50</td>\n      <td>bus_service</td>\n      <td>97.0</td>\n      <td>night_dawn</td>\n      <td>9011014505000000</td>\n      <td>5</td>\n      <td>141010001054458148</td>\n      <td>0</td>\n      <td>...</td>\n      <td>Brunnsparken</td>\n      <td>Stenpiren</td>\n      <td>145235353</td>\n      <td>145235353</td>\n      <td>LINESTRING (319300.968 6400118.943, 318713.953...</td>\n      <td>2022-07-31</td>\n      <td>Sunday</td>\n      <td>weekend</td>\n      <td>2022-07-25</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9022014001760012</td>\n      <td>9022014006242004</td>\n      <td>50</td>\n      <td>bus_service</td>\n      <td>97.0</td>\n      <td>night_dawn</td>\n      <td>9011014505000000</td>\n      <td>5</td>\n      <td>141010001054458148</td>\n      <td>0</td>\n      <td>...</td>\n      <td>Brunnsparken</td>\n      <td>Stenpiren</td>\n      <td>145235353</td>\n      <td>145235353</td>\n      <td>LINESTRING (319300.968 6400118.943, 318713.953...</td>\n      <td>2022-08-06</td>\n      <td>Saturday</td>\n      <td>weekend</td>\n      <td>2022-08-01</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9022014001760012</td>\n      <td>9022014006242004</td>\n      <td>50</td>\n      <td>bus_service</td>\n      <td>97.0</td>\n      <td>night_dawn</td>\n      <td>9011014505000000</td>\n      <td>5</td>\n      <td>141010001054458148</td>\n      <td>0</td>\n      <td>...</td>\n      <td>Brunnsparken</td>\n      <td>Stenpiren</td>\n      <td>145235353</td>\n      <td>145235353</td>\n      <td>LINESTRING (319300.968 6400118.943, 318713.953...</td>\n      <td>2022-08-07</td>\n      <td>Sunday</td>\n      <td>weekend</td>\n      <td>2022-08-01</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9022014001760012</td>\n      <td>9022014006242004</td>\n      <td>50</td>\n      <td>bus_service</td>\n      <td>97.0</td>\n      <td>night_dawn</td>\n      <td>9011014505000000</td>\n      <td>5</td>\n      <td>141010001054458148</td>\n      <td>0</td>\n      <td>...</td>\n      <td>Brunnsparken</td>\n      <td>Stenpiren</td>\n      <td>145235353</td>\n      <td>145235353</td>\n      <td>LINESTRING (319300.968 6400118.943, 318713.953...</td>\n      <td>2022-08-13</td>\n      <td>Saturday</td>\n      <td>weekend</td>\n      <td>2022-08-08</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9022014001760012</td>\n      <td>9022014006242004</td>\n      <td>50</td>\n      <td>bus_service</td>\n      <td>97.0</td>\n      <td>night_dawn</td>\n      <td>9011014505000000</td>\n      <td>5</td>\n      <td>141010001054458148</td>\n      <td>0</td>\n      <td>...</td>\n      <td>Brunnsparken</td>\n      <td>Stenpiren</td>\n      <td>145235353</td>\n      <td>145235353</td>\n      <td>LINESTRING (319300.968 6400118.943, 318713.953...</td>\n      <td>2022-08-14</td>\n      <td>Sunday</td>\n      <td>weekend</td>\n      <td>2022-08-08</td>\n      <td>32</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Merge the links_pt_0 with the preprocessed calendar_dates\n",
    "all_trips_gtfs = pd.merge(links_pt_0, calendar_dates_gtfs[[\n",
    "    'service_id', 'date', 'day_week', 'day_type', 'week_start', 'week_number']],\n",
    "                          on='service_id',\n",
    "                          how='inner')\n",
    "\n",
    "# Step 8 (optional): Display the temporary results\n",
    "all_trips_gtfs.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 9: Filter the data by selecting the period with the highest concentration of trips\n",
    "filtered_trips_gtfs = all_trips_gtfs[all_trips_gtfs['date'].between('2022-09-01', '2022-12-10')]\n",
    "\n",
    "# Step 10: Create the 'week_count' column to contain information about the number of weeks each service operates\n",
    "filtered_trips_gtfs['week_count'] = filtered_trips_gtfs.groupby(['route_id', 'service_id'])['week_number'].transform('nunique')\n",
    "\n",
    "# Step 11: Filter the frequent services of each route\n",
    "frequent_services_routes = (filtered_trips_gtfs.groupby(['route_id', 'week_count'], as_index=False)\n",
    "                            .size()\n",
    "                            .reset_index(names='route_id_count')\n",
    "                            .sort_values(['route_id', 'route_id_count'], ascending=[True, False])\n",
    "                            .groupby('route_id')\n",
    "                            .apply(lambda x: x.head(2))\n",
    "                            .reset_index(drop=True))\n",
    "\n",
    "# Step 12: Merge the results\n",
    "filtered_services_routes = pd.merge(filtered_trips_gtfs, frequent_services_routes,\n",
    "                                    on=['route_id', 'week_count'], how='inner')\n",
    "\n",
    "# Step 13 (optional): Display the temporary results\n",
    "print(filtered_services_routes.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Nodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocess the data to obtain information on each route passing through each stop\n",
    "# Step 1: Filter columns from the DataFrame\n",
    "nodes_pt_0 = nodes_pt_0[['stop_id', 'stop_name', 'place_id', 'osmid', 'geometry']]\n",
    "\n",
    "# Step 2: Merge nodes_pt_0 with target and source stop_ids\n",
    "nodes_pt_1 = pd.concat([\n",
    "    nodes_pt_0.merge(filtered_services_routes [['route_id','target', 'route_short_name','mode', 'direction_id']], left_on='stop_id', right_on='target', how='inner'),\n",
    "    nodes_pt_0.merge(filtered_services_routes [['route_id','source', 'route_short_name','mode', 'direction_id']], left_on='stop_id', right_on='source', how='inner')\n",
    "])\n",
    "\n",
    "# Step 3: Change NaN values to 0\n",
    "nodes_pt_1['osmid'] = nodes_pt_1['osmid'].fillna(0)\n",
    "\n",
    "# Step 4: Display the data\n",
    "nodes_pt_1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 5: create node_id column\n",
    "nodes_pt_1 ['node_id'] = nodes_pt_1 ['stop_id'].astype(str) + '_'+ nodes_pt_1 ['route_id'].astype(str)\n",
    "\n",
    "#Step 6: combine duplicates and transform the Dataframe to a GeoDataFrame\n",
    "nodes_pt_1 = gpd.GeoDataFrame(nodes_pt_1[['node_id','stop_id', 'route_id', 'route_short_name', 'stop_name',\n",
    "                                          'place_id', 'mode', 'direction_id','osmid', 'geometry']]).drop_duplicates(['node_id', 'route_id'])\n",
    "\n",
    "# Step 7: Display the results\n",
    "nodes_pt_1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Step 7 (optional): export to the DB\n",
    "nodes_pt_1.to_postgis('nodes_pt_1_2', engine, schema='pt_1_mdirections_mstops_mroutes', if_exists ='replace')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Links"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "# Step1: Group by specified columns and count the links\n",
    "frequency_by_date_groupby = filtered_services_routes.groupby(\n",
    "    ['source', 'target', 'route_id', 'date', 'time_period']\n",
    ").size().reset_index(name='links_count')\n",
    "\n",
    "# Step 2: Merge the grouped data with the original dataframe\n",
    "frequency_links = pd.merge(\n",
    "    filtered_services_routes,\n",
    "    frequency_by_date_groupby,\n",
    "    on=['source', 'target', 'route_id', 'date', 'time_period']\n",
    ")\n",
    "\n",
    "# Step 3 (optional): Display the temporary results\n",
    "frequency_links.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate Frequencies\n",
    "# Step 4: Calculate the number of links\n",
    "frequency_links['frequency_date'] = 10800 / frequency_links['links_count']\n",
    "\n",
    "# Step 5: Calculate mean frequency by day of the week\n",
    "frequency_links['frequency_dayweek'] = frequency_links.groupby(\n",
    "    ['source', 'target', 'route_id', 'day_week', 'time_period']\n",
    ")['frequency_date'].transform('mean')\n",
    "\n",
    "# Step 6: Calculate mean frequency by day type\n",
    "frequency_links['frequency_daytype'] = frequency_links.groupby(\n",
    "    ['source', 'target', 'route_id', 'day_type', 'time_period']\n",
    ")['frequency_date'].transform('mean')\n",
    "\n",
    "# Step 7: Filter the first link by day of the week and time period, and rename columns\n",
    "frequency_links_l1 = frequency_links.groupby(\n",
    "    ['source', 'target', 'route_id', 'date', 'time_period']\n",
    ").first().reset_index().drop_duplicates(\n",
    "    subset=['source', 'target', 'route_id', 'day_week', 'time_period']\n",
    ").rename(columns={\n",
    "    'source': 'stop_id_source',\n",
    "    'target': 'stop_id_target'\n",
    "})\n",
    "\n",
    "# Step 8 (optional): Display the temporary results\n",
    "frequency_links_l1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Clean and organize the data\n",
    "# Step 9: Add node_id columns\n",
    "frequency_links_l1['node_id_source'] = frequency_links_l1['stop_id_source']\n",
    "frequency_links_l1['node_id_target'] = frequency_links_l1['stop_id_target']\n",
    "\n",
    "# Step 10: Concatenate node_id and route_id to create source and target columns\n",
    "frequency_links_l1['source'] = frequency_links_l1['node_id_source'].astype(str) + '_' + frequency_links_l1['route_id'].astype(str)\n",
    "frequency_links_l1['target'] = frequency_links_l1['node_id_target'].astype(str) + '_' + frequency_links_l1['route_id'].astype(str)\n",
    "\n",
    "# Step 11: Select the desired columns\n",
    "links_pt_1 = frequency_links_l1[[\n",
    "    'source', 'target', 'time_distance', 'stop_id_source', 'stop_id_target',\n",
    "    'node_id_source', 'node_id_target', 'route_id', 'route_short_name',\n",
    "    'stop_name_source', 'stop_name_target', 'place_id_source', 'place_id_target',\n",
    "    'mode', 'direction_id', 'stop_sequence', 'time_period', 'day_week', 'day_type',\n",
    "    'frequency_dayweek', 'frequency_daytype', 'geometry'\n",
    "]]\n",
    "\n",
    "# Step 12: Display the first few rows with the results\n",
    "links_pt_1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 13 (optional): Set Geometry and export the table to the DB\n",
    "links_pt_1 = gpd.GeoDataFrame(links_pt_1, geometry='geometry', crs='3006')\n",
    "links_pt_1.to_postgis('links_pt_1_long_2', engine, schema='pt_1_mdirections_mstops_mroutes', if_exists ='replace')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transfers\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Same stop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocess the Data\n",
    "# Step 1: Create a copy of the nodes table\n",
    "nodes_transfer_same_stop = nodes_pt_1[['node_id', 'stop_id', 'place_id', 'geometry']].copy()\n",
    "\n",
    "#Step 2 (optional): display the results\n",
    "nodes_transfer_same_stop.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 3: Merge the stops in order to create the transfers\n",
    "# Source\n",
    "stop_routes_source = nodes_transfer_same_stop.rename(columns={'node_id': 'source', 'stop_id': 'target'}).drop_duplicates()\n",
    "\n",
    "# Target\n",
    "stop_routes_target = pd.merge(nodes_transfer_same_stop,\n",
    "                              nodes_pt_1[['node_id']],\n",
    "                              on='node_id',\n",
    "                              how='inner').rename(columns={'stop_id': 'source', 'node_id': 'target'}).drop_duplicates()\n",
    "\n",
    "# Step 4: Create the transfers same stop table\n",
    "transfers_same_stop = pd.merge(stop_routes_source, stop_routes_target, how='outer')\n",
    "\n",
    "#Step 5 (optional): Display the results\n",
    "transfers_same_stop.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the transfers\n",
    "# Step 6: Merge the table with the frequency of the links table\n",
    "transfers_same_stop = pd.merge(\n",
    "    transfers_same_stop,\n",
    "    links_pt_1[['target', 'day_week', 'day_type', 'frequency_dayweek', 'frequency_daytype']],\n",
    "    on='target',\n",
    "    how='outer'\n",
    ").drop_duplicates(subset=['source', 'target'])\n",
    "\n",
    "#Step 7 (optional): Display the results\n",
    "transfers_same_stop.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 5: Replace 0 with NaN and vice versa in frequency columns\n",
    "freq_columns = [col for col in transfers_same_stop_merge.columns if col.startswith('frequency')]\n",
    "transfers_same_stop_merge[freq_columns] = transfers_same_stop_merge[freq_columns].replace({0: np.nan, np.nan: 0})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 6: Filter final columns for transfers_same_stop table\n",
    "transfers_same_stop = transfers_same_stop_merge[[\n",
    "    'source', 'target', 'day_week', 'day_type', 'frequency_dayweek', 'frequency_daytype', 'geometry'\n",
    "]]\n",
    "transfers_same_stop.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 7 (optional): Set Geometry and export the table to the DB\n",
    "transfers_same_stop = gpd.GeoDataFrame(transfers_same_stop, geometry='geometry', crs='3006')\n",
    "transfers_same_stop.to_postgis('transfers_same_stop_pt_1_long_2', engine, schema='pt_1_mdirections_mstops_mroutes', if_exists ='replace')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Different stops"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Preprocess the Data\n",
    "# Step 1: Create a copy of the nodes table\n",
    "nodes_transfer_diff_stop = nodes_pt_1[['node_id', 'stop_id', 'geometry']].copy()\n",
    "\n",
    "# Step 2 (optional): Display the results\n",
    "nodes_transfer_diff_stop.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create the buffers\n",
    "# Step 3: Create a buffer column and set it as geometry\n",
    "nodes_transfer_diff_stop['buffer'] = nodes_transfer_diff_stop['geometry'].buffer(85)\n",
    "nodes_transfer_diff_stop = nodes_transfer_diff_stop.set_geometry('buffer',\n",
    "                                                                 crs='EPSG:3006')\n",
    "\n",
    "# Step 4: found the intersections among the buffers\n",
    "nodes_transfer_diff_stop = gpd.overlay(nodes_transfer_diff_stop,\n",
    "                                       nodes_transfer_diff_stop,\n",
    "                                       how='intersection').rename(columns={'node_id_1':'source',\n",
    "                                                                           'node_id_2':'target',\n",
    "                                                                           'stop_id_1':'stop_id_source',\n",
    "                                                                           'stop_id_2':'stop_id_target',\n",
    "                                                                           'geometry_1': 'geometry_source',\n",
    "                                                                           'geometry_2': 'geometry_target'}).dropna(subset=['source'])\n",
    "# Step 5 (optional): Display the results\n",
    "nodes_transfer_diff_stop.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create the geometry\n",
    "# Step 6: Create linstrings between the intersections\n",
    "nodes_transfer_diff_stop['geometry'] = nodes_transfer_diff_stop.apply(lambda row: LineString([[row.geometry_source.x,\n",
    "                                                                                               row.geometry_source.y],\n",
    "                                                                                                [row.geometry_target.x,\n",
    "                                                                                                 row.geometry_target.y]]) if row.geometry_target is not None else None,\n",
    "                                                                      axis=1)\n",
    "# Step 7: Set the length of the linestring\n",
    "nodes_transfer_diff_stop['length'] = nodes_transfer_diff_stop['geometry'].length\n",
    "nodes_transfer_diff_stop['time_distance'] = nodes_transfer_diff_stop['length'] / 1.2\n",
    "\n",
    "# Step 8 (optional): Display the results\n",
    "nodes_transfer_diff_stop.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Filter and organize the tables\n",
    "# Step 9: Filter the transfers between different stops\n",
    "transfers_diff_stop = nodes_transfer_diff_stop[nodes_transfer_diff_stop['length'] > 0]\n",
    "\n",
    "# Step 10: Drop the duplicates of symmetric pairs\n",
    "transfers_diff_stop ['symmetric_pairs'] = transfers_diff_stop[['source',\n",
    "                                                               'target']].apply(lambda x: '-'.join(sorted(x)),\n",
    "                                                                                axis=1)\n",
    "transfers_diff_stop = transfers_diff_stop.drop_duplicates(subset = ['symmetric_pairs'])\n",
    "\n",
    "# Step 11: Filter the necessary columns\n",
    "transfers_diff_stop = transfers_diff_stop [['stop_id_source',\n",
    "                                            'stop_id_target',\n",
    "                                            'geometry',\n",
    "                                            'length',\n",
    "                                            'time_distance']].rename(columns={'stop_id_source':'source',\n",
    "                                                                              'stop_id_target':'target'}).drop_duplicates()\n",
    "# Step 12 (optional): Display the results\n",
    "transfers_diff_stop.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 6 (optional): Set Geometry and export the table to the DB\n",
    "transfers_diff_stop = gpd.GeoDataFrame(transfers_diff_stop, geometry='geometry', crs='3006')\n",
    "transfers_diff_stop.to_postgis('transfers_diff_stop_pt_1_long_2', engine, schema='pt_1_mdirections_mstops_mroutes', if_exists ='replace')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}